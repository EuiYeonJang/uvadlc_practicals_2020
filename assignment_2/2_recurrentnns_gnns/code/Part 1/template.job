#!/bin/bash

#SBATCH --partition=gpu_shared_course
#SBATCH --gres=gpu:1
#SBATCH --job-name=Q1.3
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=3
#SBATCH --time=04:00:00
#SBATCH --mem=32000M
#SBATCH --array=1-16%8
#SBATCH --output=slurm_array_testing_%A_%a.out

module purge
module load 2019
module load Python/3.7.5-foss-2019b
module load CUDA/10.1.243
module load cuDNN/7.6.5.32-CUDA-10.1.243
module load NCCL/2.5.6-CUDA-10.1.243
module load Anaconda3/2018.12

# Activate your environment
source activate dl2020


$HPARAMS_FILE=./hyperparam.txt
CHECKPOINTDIR=./summaries/array_job_${SLURM_ARRAY_JOB_ID}

# Good practice: define your directory where to save the models, and copy the job file to it
# Run your code
srun python -u train.py \
               $(head -$SLURM_ARRAY_TASK_ID $HPARAMS_FILE | tail -1)